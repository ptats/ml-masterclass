{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run in terminal\n",
    "\n",
    "`pip uninstall enum34`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastai==1.0.61\n",
      "  Downloading fastai-1.0.61-py3-none-any.whl (239 kB)\n",
      "\u001b[K     |████████████████████████████████| 239 kB 10.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==1.0.61) (4.9.1)\n",
      "Requirement already satisfied: requests in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==1.0.61) (2.24.0)\n",
      "Collecting dataclasses; python_version < \"3.7\"\n",
      "  Downloading dataclasses-0.7-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: packaging in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==1.0.61) (20.4)\n",
      "Requirement already satisfied: torch>=1.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==1.0.61) (1.4.0)\n",
      "Requirement already satisfied: pandas in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==1.0.61) (0.25.3)\n",
      "Requirement already satisfied: spacy>=2.0.18; python_version < \"3.8\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==1.0.61) (2.1.8)\n",
      "Collecting fastprogress>=0.2.1\n",
      "  Downloading fastprogress-1.0.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: Pillow in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==1.0.61) (6.2.1)\n",
      "Requirement already satisfied: scipy in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==1.0.61) (1.4.1)\n",
      "Requirement already satisfied: torchvision in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==1.0.61) (0.5.0)\n",
      "Requirement already satisfied: matplotlib in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==1.0.61) (3.2.1)\n",
      "Collecting numexpr\n",
      "  Downloading numexpr-2.7.1-cp36-cp36m-manylinux1_x86_64.whl (162 kB)\n",
      "\u001b[K     |████████████████████████████████| 162 kB 21.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nvidia-ml-py3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==1.0.61) (7.352.0)\n",
      "Requirement already satisfied: pyyaml in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==1.0.61) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==1.0.61) (1.18.5)\n",
      "Collecting bottleneck\n",
      "  Downloading Bottleneck-1.3.2.tar.gz (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 1.8 MB/s  eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from beautifulsoup4->fastai==1.0.61) (2.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->fastai==1.0.61) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->fastai==1.0.61) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->fastai==1.0.61) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->fastai==1.0.61) (1.25.10)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from packaging->fastai==1.0.61) (2.4.7)\n",
      "Requirement already satisfied: six in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from packaging->fastai==1.0.61) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from pandas->fastai==1.0.61) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from pandas->fastai==1.0.61) (2.8.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (1.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (1.0.2)\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (7.0.8)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (0.9.6)\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (0.2.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (2.0.3)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (2.0.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (0.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib->fastai==1.0.61) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib->fastai==1.0.61) (1.2.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from thinc<7.1.0,>=7.0.8->spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (4.48.2)\n",
      "Building wheels for collected packages: bottleneck\n",
      "  Building wheel for bottleneck (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bottleneck: filename=Bottleneck-1.3.2-cp36-cp36m-linux_x86_64.whl size=315840 sha256=98dc7a6965eaec502da7fee56d1f7d1546c64e82643f0e36dbd0a2a1f8062a64\n",
      "  Stored in directory: /home/azureuser/.cache/pip/wheels/f7/a7/14/9be836efed01ac0eb3c125ac006c143b55ebf689269877d0e8\n",
      "Successfully built bottleneck\n",
      "Installing collected packages: dataclasses, fastprogress, numexpr, bottleneck, fastai\n",
      "Successfully installed bottleneck-1.3.2 dataclasses-0.7 fastai-1.0.61 fastprogress-1.0.0 numexpr-2.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install fastai==1.0.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "import pathlib\n",
    "from azureml.core import Workspace, Datastore, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1.0 Create your own image classifier - Dataset Creation**\n",
    "\n",
    "by: Paula Tattam. An extraction of Fastai [Lesson 1](https://https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson1-pets.ipynb) and [Lesson 2](https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson2-download.ipynb)\n",
    "\n",
    "In this workshop you will get to create your own image classification dataset using google images. You will then build and train your own image classifier using the [fastai V1 library](https://www.fast.ai/2018/10/02/fastai-ai/). fastai is a python machine learning library built on top of the popular [PyTorch v1.0](https://engineering.fb.com/ai-research/facebook-accelerates-ai-development-with-new-partners-and-production-capabilities-for-pytorch-1-0/) machine learning framework.\n",
    "\n",
    "Fastai is a library that allows you to rapidly build and train your own machine learning models utilising transfer learning from a range of current state of the art models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 1: Pick a classification task**\n",
    "For step 1 make up an image classification task. It can be any topic of your choice but the images will need to be available through [google images.](https://images.google.com/?gws_rd=ssl) For example:\n",
    "\n",
    "*   Disney character classifier\n",
    "*   Hotdogs or legs\n",
    "*   Big cat classifier (tigers, lions, cheetahs, etc...)\n",
    "\n",
    "Please try keep it PG and don't pick too many different classes as you will need to repeat the below step for each class.\n",
    "\n",
    "Google image search allows you to exclude certain words in a search, combine searchs and a number of other operations.\n",
    "\n",
    "For example, to search dog but exlcude wolves, use the `-` operator:\n",
    "\n",
    "`dog -wolves -wolf`\n",
    "\n",
    "See more options [here](https://support.google.com/websearch/answer/2466433?visit_id=637175902163553047-3698874010&p=adv_operators&hl=en&rd=1).\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 2: Download URLs**\n",
    "\n",
    "You will need to download each image URL to a file. This can be done by using a small snippet of JavaScript. Open the javascript console in either chrome or firefox as follows:\n",
    "\n",
    "* Chrome: `ctrl+shift+j` (macOS: `Cmd+Opt+j`)\n",
    "* Firefox: `ctrl+shit+k` (macOS: `Cmd+Opt+k`)\n",
    "\n",
    "This will open up a window where you will paste the below code snippet. Before you paste the code, scroll down in your search results window a few times to load images. Only the displayed search image urls will be copied.\n",
    "\n",
    "```javascript\n",
    "urls=Array.from(document.querySelectorAll('.rg_i')).map(el=> el.hasAttribute('data-src')?el.getAttribute('data-src'):el.getAttribute('data-iurl'));\n",
    "window.open('data:text/csv;charset=utf-8,' + escape(urls.join('\\n')));\n",
    "```\n",
    "\n",
    "Repeat this step for each classification category that you have chosen. Once the file is downloaded, rename as per the following convention:\n",
    "\n",
    "`urls_<label>.csv`\n",
    "\n",
    "For example, if you are building a disney classifier you would name the files as follows:\n",
    "\n",
    "`urls_mickey.csv, urls_minnie.csv etc...`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 3: Create directories and upload files**\n",
    "\n",
    "Choose an appropriate name for your directory and create a list of your class labels. Edit the below cells as noted and run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE ME: add your labels as per the label used for the csv file\n",
    "labels = [\"zoro\", \"sanji\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE ME: name as per your classifcation task\n",
    "name = \"one_piece_crew\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "  path = Path(f'data/{name}') \n",
    "  dest = path/label\n",
    "  dest.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/one_piece_crew/sanji'), PosixPath('data/one_piece_crew/zoro')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we upload the csv files. Open the side menu, press 'Upload' and select your files. Don't forget to move them into the newly created directory above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 4: Download images**\n",
    "\n",
    "Next you will need to download the images for each label. Luckily, fast.ai have a function specifically designed for this. As long as you followed the naming convention above for the csv file, this will block of code should just work.\n",
    "\n",
    "In this example, we set the image donwload limit to 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for label in labels:\n",
    "  filename = f\"urls_{label}.csv\"\n",
    "  dest = path/label\n",
    "  download_images(path/filename, dest, max_pics=200)\n",
    "  os.remove(path/filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will need to remove any images that cannot be opened. The following block of code does this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zoro\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sanji\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for label in labels:\n",
    "  print(label)\n",
    "  verify_images(path/label, delete=True, max_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Create Dataset in Azure\n",
    "\n",
    "Next you will create a dataset in Azure from you downloded images.\n",
    "\n",
    "First, you need to upload these files to the azure blobstore. Azure automatically creates a default blobstore for you to use when a workspace is created. To find this name you can navigate to the studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_name = 'workspaceblobstore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n",
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code PQ65SRJXQ to authenticate.\n",
      "You have logged in. Now let us find all the subscriptions to which you have access...\n",
      "Interactive authentication successfully completed.\n"
     ]
    }
   ],
   "source": [
    "workspace = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = Datastore.get(workspace, datastore_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure has different two types of datasets that include:\n",
    "\n",
    "* FileDatasets - for images or videos\n",
    "* TabularDatasets - for structured data (eg. csv files, sql tables, etc...)\n",
    "\n",
    "For this task we will need to create a FileDataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "datastore.upload(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_paths = [(datastore, name)]\n",
    "image_dataset = Dataset.File.from_files(path=datastore_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE ME: name as per your classifcation task\n",
    "dataset_name = \"OnePiece\"\n",
    "description = \"Image dataset for anime one piece characters. Only includes Sanji and Zoro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', 'one_piece_crew')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"37f88cdc-96f6-4e00-879d-845f4d379cdf\",\n",
       "    \"name\": \"OnePiece\",\n",
       "    \"version\": 1,\n",
       "    \"description\": \"Image dataset for anime one piece characters. Only includes Sanji and Zoro\",\n",
       "    \"workspace\": \"Workspace.create(name='ml-masterclass-ws', subscription_id='e36c4f51-a63e-4dd2-845f-26e8fea75d45', resource_group='ml-masterclass-rg')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataset.register(\n",
    "    workspace=workspace,\n",
    "    name=dataset_name,\n",
    "    description=description,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to the azure machine learnings studio and see your newly created dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
